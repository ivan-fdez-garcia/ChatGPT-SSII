# Importing necessary modules
import openai
import os
import datetime
from time import sleep
from flask import Flask, request, jsonify
from openai.types.beta import assistant
from openai.types.beta.threads import annotation
from packaging.version import parse

# ------------------------------------------------------------

# Initializing Flask app
app = Flask(__name__)

# Initializing OpenAI client with API key and assistant ID
client = openai.OpenAI(api_key=os.environ['API_KEY'])
assistant_id = os.environ['ASSISTANT_ID']

# ------------------------------------------------------------


# Route to start a conversation
@app.route('/start', methods=['GET'])
def start_conversation():
  # Creating a new thread
  thread = client.beta.threads.create()
  return jsonify({"thread_id": thread.id})


# ------------------------------------------------------------


# Route to generate response
@app.route('/chat', methods=['POST'])
def chat():
  # Getting user data from request
  user_data = request.json
  thread_id = user_data.get('thread_id')
  user_input = user_data.get('message', '')

  # Error handling for missing thread_id or user input
  if not thread_id:
    return jsonify({"error": "Missing thread_id"}), 400
  if not user_input:
    return jsonify({"error": "Missing user input"}), 400

  # Sending user input to the thread
  client.beta.threads.messages.create(thread_id=thread_id,
                                      role="user",
                                      content=user_input)

  # Running the thread to get AI response
  run = client.beta.threads.runs.create(thread_id=thread_id,
                                        assistant_id=assistant_id)

  # Waiting for the run to complete
  while run.status != "completed":
    run = client.beta.threads.runs.retrieve(thread_id=thread_id, run_id=run.id)
    print(run.status)

    # Handling failure status
    if run.status == 'failed':
      return jsonify({"response": "Se ha producido un error"})

    # Sleeping for 1 second before checking again
    sleep(1)

  # Fetching messages from the thread
  messages = client.beta.threads.messages.list(thread_id=thread_id)
  message_content = messages.data[0].content
  response = []

  # Creating directory for generated files
  date = datetime.datetime.now().date()
  output_dir = './generated_files/' + str(date)
  if not os.path.exists(output_dir):
    os.makedirs(output_dir)

  # Processing message content (text or image files)
  for content in message_content:
    # Processing text messages
    if content.type == 'text':
      # Processing possible files generated by code interpreter
      for annotation in content.text.annotations:
        if annotation.type == 'file_path':
          response.append(
            'Se ha generado un archivo, comprueba la carpeta de salida.\n'
          )
          annotation_data = client.files.content(annotation.file_path.file_id)
          annotation_data_bytes = annotation_data.read()
          filename = annotation.text.split('/')[-1]
          with open(output_dir + '/' + filename, 'wb') as file:
            file.write(annotation_data_bytes)
      response.append(content.text.value)
    elif content.type == 'image_file':
      # Processing image files
      file_id = content.image_file.file_id
      image_data = client.files.content(file_id)
      image_data_bytes = image_data.read()
      with open(output_dir + '/' + file_id + '.png', "wb") as file:
        file.write(image_data_bytes)
      response.append(
          'Se ha generado una imagen, comprueba la carpeta de salida.\n')

  # Joining response messages into a single string
  final_response = "\n".join(response)
  return jsonify({"response": final_response})


# ------------------------------------------------------------

# Running the Flask app
if __name__ == '__main__':
  app.run(host='0.0.0.0', port=8080)
